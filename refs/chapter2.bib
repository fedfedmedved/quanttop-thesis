@article{Gotz2015,
author = {G{\"{o}}tz, Markus and Bodenstein, Christian and Riedel, Morris},
doi = {10.1145/2834892.2834894},
file = {:home/p3732/MA/papers/HPDBSCAN (paper).pdf:pdf},
title = {{HPDBSCAN – Highly Parallel DBSCAN}},
year = {2015}
}
@article{Jolliffe2002,
abstract = {Principal component analysis is central to the study of multivariate data. Although one of the earliest multivariate techniques it continues to be the subject of much research, ranging from new model- based approaches to algorithmic ideas from neural networks. It is extremely versatile with applications in many disciplines. The first edition of this book was the first comprehensive text written solely on principal component analysis. The second edition updates and substantially expands the original version, and is once again the definitive text on the subject. It includes core material, current research and a wide range of applications. Its length is nearly double that of the first edition. Researchers in statistics, or in other fields that use principal component analysis, will find that the book gives an authoritative yet accessible account of the subject. It is also a valuable resource for graduate courses in multivariate analysis. The book requires some knowledge of matrix algebra. Ian Jolliffe is Professor of Statistics at the University of Aberdeen. He is author or co-author of over 60 research papers and three other books. His research interests are broad, but aspects of principal component analysis have fascinated him and kept him busy for over 30 years.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Jolliffe, I T},
doi = {10.1007/b98835},
eprint = {arXiv:1011.1669v3},
file = {:home/p3732/MA/papers/Jolliffe I. Principal Component Analysis (2ed., Springer, 2002)(518s){\_}MVsa{\_}.pdf:pdf},
isbn = {0-387-95442-2},
issn = {01621459},
journal = {Springer Series in Statistics},
keywords = {principal component analysis,statistical theory methods},
pages = {487},
pmid = {21674720},
title = {{Principal Component Analysis, Second Edition}},
url = {http://link.springer.com/10.1007/b98835},
volume = {98},
year = {2002}
}
@inproceedings{Arthur2007,
author = {Arthur, David and Vassilvitskii, Sergei},
booktitle = {Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms},
pages = {1027--1035},
publisher = {Society for Industrial and Applied Mathematics Philadelphia},
title = {{k-means++: The Advantages of Careful Seeding}},
url = {http://portal.acm.org/citation.cfm?id=1283494},
year = {2007}
}
@book{Manning2012,
author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"{u}}tze, Hinrich},
doi = {10.1017/CBO9780511809071},
file = {:home/p3732/Downloads/irbookonlinereading.pdf:pdf},
isbn = {9780511809071},
publisher = {Cambridge University Press},
title = {{Introduction to Information Retrieval}},
url = {https:/978-0521865715/nlp.stanford.edu/IR-book/},
year = {2012}
}
@article{Heer2010,
abstract = {A survey of powerful visualization techniques, from the obvious to the obscure.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Heer, Jeffrey and Bostock, Michael and Ogievetsky, Vadim},
doi = {10.1145/1743546},
eprint = {arXiv:1011.1669v3},
file = {:home/p3732/MA/papers/A Tour Through the Visualization Zoo (p59-heer).pdf:pdf},
isbn = {00010782},
issn = {00010782},
journal = {Communications of the ACM},
number = {5},
pages = {59--67},
pmid = {15224215},
title = {{A Tour through the Visualization Zoo}},
volume = {53},
year = {2010}
}
@inproceedings{dbscan,
author = {Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"{o}}rg and Xu, Xiaowei},
booktitle = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
doi = {10.1.1.121.9220},
file = {:home/p3732/MA/papers/dbscan (10.1.1.121.9220).pdf:pdf},
pages = {226----231},
publisher = {AAAI Press},
title = {{A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise}},
year = {1996}
}
@article{Gan2015,
abstract = {DBSCAN is a popular method for clustering multi-dimensional objects. Just as notable as the method's vast success is the research community's quest for its efficient computation. The original KDD'96 paper claimed an algorithm with O(n log n) running time, where n is the number of objects. Unfortunately, this is a mis-claim; and that algorithm actually requires O(n 2) time. There has been a fix in 2D space, where a genuine O(n log n)-time algorithm has been found. Looking for a fix for dimensionality d ≥ 3 is currently an important open problem. In this paper, we prove that for d ≥ 3, the DBSCAN problem requires Ω(n 4/3) time to solve, unless very significant breakthroughs—ones widely believed to be impossible—could be made in theoretical computer science. This (i) explains why the community's search for fixing the aforementioned mis-claim has been futile for d ≥ 3, and (ii) indicates (sadly) that all DBSCAN algorithms must be intolerably slow even on moderately large n in practice. Surprisingly, we show that the running time can be dramatically brought down to O(n) in expectation regardless of the dimensionality d, as soon as slight inaccuracy in the clustering results is permitted. We formalize our findings into the new notion of $\rho$-approximate DBSCAN, which we believe should replace DBSCAN on big data due to the latter's computational intractability.},
author = {Gan, Junhao and Tao, Yufei},
doi = {10.1145/2723372.2737792},
file = {:home/p3732/MA/papers/sigmod15-dbscan.pdf:pdf},
isbn = {9781450327589},
journal = {Sigmod},
keywords = {10,4 snake-shaped clusters,algorithm,dbscan,density-based clustering,examples of density-based clustering,figure 1,from,the left one contains,while the right one},
pages = {519--530},
title = {{DBSCAN Revisited: Mis-Claim, Un-Fixablility, and Approxmimation}},
url = {http://dl.acm.org/citation.cfm?doid=2723372.2737792},
year = {2015}
}
@article{Aloise2009,
abstract = {A recent proof of NP-hardness of Euclidean sum-of-squares clustering, due to Drineas et al. (Mach. Learn. 56:9–33, 2004), is not valid. An alternate short proof is pro-vided.},
author = {Aloise, Daniel and Deshpande, Amit and Hansen, Pierre and Popat, Preyas},
doi = {10.1007/s10994-009-5103-0},
file = {:home/p3732/MA/papers/Aloise2009{\_}Article{\_}NP-hardnessOfEuclideanSum-of-s.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Clustering,Complexity,Sum-of-squares},
number = {2},
pages = {245--248},
title = {{NP-hardness of Euclidean sum-of-squares clustering}},
volume = {75},
year = {2009}
}
@article{sne,
author = {Hinton, G.E. and Roweis, S.T.},
file = {:home/p3732/MA/papers/SNE (2276-stochastic-neighbor-embedding).pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {833--840},
title = {{Stochastic Neighbor Embedding}},
url = {http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf},
volume = {15},
year = {2002}
}
@techreport{coil20,
author = {Nene, S.A. and Nayar, S.K. and Murase, H.},
file = {:home/p3732/MA/papers/Columbia Object Image Library (COIL-20) (Nene{\_}TR96).pdf:pdf},
institution = {Columbia University},
title = {{Columbia Object Image Library (COIL-20)}},
url = {http://www1.cs.columbia.edu/CAVE/publications/pdfs/Nene{\_}TR96.pdf},
year = {1996}
}
@inproceedings{Yianilos1993,
author = {Yianilos, Peter},
booktitle = {Proceedings of the ACM-SIAM Symposium on Discrete Algorithms},
file = {:home/p3732/MA/papers/vantage point tree (nndatastructures).pdf:pdf},
pages = {311--321},
title = {{Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces}},
url = {http://web.cs.iastate.edu/{~}honavar/nndatastructures.pdf},
year = {1993}
}
