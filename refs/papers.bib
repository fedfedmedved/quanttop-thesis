@article{Lloyd1982,
abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for quanta, , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.},
author = {Lloyd, Stuart P.},
doi = {10.1109/TIT.1982.1056489},
file = {:home/pet/MA/papers/Least Squares Quantization in PCM (lloyd57).pdf:pdf},
isbn = {00189448 (ISSN)},
issn = {15579654},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {129--137},
title = {{Least Squares Quantization in PCM}},
volume = {28},
year = {1982}
}
@article{Pezzotti2018,
abstract = {The t-distributed Stochastic Neighbor Embedding (tSNE) algorithm has become in recent years one of the most used and insightful techniques for the exploratory data analysis of high-dimensional data. tSNE reveals clusters of high-dimensional data points at different scales while it requires only minimal tuning of its parameters. Despite these advantages, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of tSNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the tSNE embedding for large datasets. In this work, we present a novel approach to the minimization of the tSNE objective function that heavily relies on modern graphics hardware and has linear computational complexity. Our technique does not only beat the state of the art, but can even be executed on the client side in a browser. We propose to approximate the repulsion forces between data points using adaptive-resolution textures that are drawn at every iteration with WebGL. This approximation allows us to reformulate the tSNE minimization problem as a series of tensor operation that are computed with TensorFlow.js, a JavaScript library for scalable tensor computations.},
archivePrefix = {arXiv},
arxivId = {1805.10817},
author = {Pezzotti, Nicola and Mordvintsev, Alexander and Hollt, Thomas and Lelieveldt, Boudewijn P. F. and Eisemann, Elmar and Vilanova, Anna},
eprint = {1805.10817},
file = {:home/pet/MA/papers/Linear tSNE Optimization for the Web (1805.10817v1).pdf:pdf},
pages = {1--6},
title = {{Linear tSNE optimization for the Web}},
url = {http://arxiv.org/abs/1805.10817},
year = {2018}
}
@article{VanDerMaaten2008,
abstract = {We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence theway in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza- tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
archivePrefix = {arXiv},
arxivId = {1307.1662},
author = {{Van Der Maaten}, L J P and Hinton, G E},
doi = {10.1007/s10479-011-0841-3},
eprint = {1307.1662},
file = {:home/pet/MA/papers/Visualizing high-dimensional data using t-sne (JMLR{\_}2008).pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization},
pages = {2579--2605},
pmid = {20652508},
title = {{Visualizing high-dimensional data using t-sne}},
url = {https://lvdmaaten.github.io/publications/papers/JMLR{\_}2008.pdf{\%}0Ahttp://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=pubmed{\&}cmd=Retrieve{\&}dopt=AbstractPlus{\&}list{\_}uids=7911431479148734548related:VOiAgwMNy20J},
volume = {9},
year = {2008}
}
@article{Maaten2014,
abstract = {The paper investigates the acceleration of t-SNE—an embedding technique that is com- monly used for the visualization of high-dimensional data in scatter plots—using two tree- based algorithms. In particular, the paper develops variants of the Barnes-Hut algorithm and of the dual-tree algorithm that approximate the gradient used for learning t-SNE em- beddings in O(N logN). Our experiments show that the resulting algorithms substantially accelerate t-SNE, and that they make it possible to learn embeddings of data sets with millions of objects. Somewhat counterintuitively, the Barnes-Hut variant of t-SNE appears to outperform the dual-tree variant.},
archivePrefix = {arXiv},
arxivId = {1307.1662},
author = {Maaten, Laurens Van Der},
doi = {10.1007/s10479-011-0841-3},
eprint = {1307.1662},
file = {:home/pet/MA/papers/Accelerating t-SNE using Tree-Based Algorithms (JMLR{\_}2014).pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {barnes-hut algorithm,dual-tree algorithm,embedding,multidimensional scaling,space-partitioning trees,t-sne},
number = {2014},
pages = {1--21},
pmid = {20652508},
title = {{Accelerating t-SNE using Tree-Based Algorithms}},
volume = {15},
year = {2014}
}
